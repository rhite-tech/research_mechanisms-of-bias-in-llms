# Replace weights_directory with either:
# * the *ABSOLUTE PATH* to where you store your weights, or
# * the huggingface repo with your weights.
# Specify probe_layer and intervene_layer according to the patching experiment.
[llama-13b]
weights_directory = /scratch-shared/tpungas/llama-13b 
name = LLaMA-13B
tokenizer_class = LlamaTokenizer
model_class = LlamaForCausalLM
layers = model.layers
probe_layer = 13
intervene_layer = 7
noperiod = False

[llama-3-8b]
weights_directory = meta-llama/Meta-Llama-3-8B
name = LLaMA-3-8b
tokenizer_class = AutoTokenizer
model_class = AutoModelForCausalLM
layers = model.layers
probe_layer = 12
intervene_layer = 8
noperiod = False

[llama-3-70b]
weights_directory = meta-llama/Meta-Llama-3-70B
name = LLaMA-3-70b
tokenizer_class = AutoTokenizer
model_class = AutoModelForCausalLM
layers = model.layers
probe_layer = 33
intervene_layer = 21
noperiod = False

[hf_key]
hf_key = ...  # replace this with your HuggingFace access token (if needed)
