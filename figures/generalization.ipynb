{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataManager\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from utils import DataManager\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from probes import LRProbe, MMProbe, CCSProbe\n",
    "import configparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "model = 'llama-13b'\n",
    "split = 0.8\n",
    "device = 'cuda:0' if t.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# layer = eval(config[model]['probe_layer'])\n",
    "layer = 12\n",
    "noperiod = eval(config[model]['noperiod'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing generalization matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_medlies  = [\n",
    "    ['experiment_cps'],\n",
    "    ['experiment_inter_stereoset'], # gender\n",
    "    ['experiment_intra_stereoset'], # gender'\n",
    "    #['experiment_inter_race_stereoset'],\n",
    "    #['experiment_intra_race_stereoset'],\n",
    "    #['experiment_inter_profession_stereoset'],\n",
    "    #['experiment_intra_profession_stereoset'],\n",
    "    #['experiment_inter_religion_stereoset'],\n",
    "    #['experiment_intra_religion_stereoset'],\n",
    "    ['likely']\n",
    "]\n",
    "\n",
    "val_datasets = [\n",
    "    'experiment_cps',\n",
    "    'experiment_inter_stereoset', # gender\n",
    "    'experiment_intra_stereoset', # gender'\n",
    "    #'experiment_inter_race_stereoset',\n",
    "    #'experiment_intra_race_stereoset',\n",
    "    #'experiment_inter_profession_stereoset',\n",
    "    #'experiment_intra_profession_stereoset',\n",
    "    #'experiment_inter_religion_stereoset',\n",
    "    #'experiment_intra_religion_stereoset',   \n",
    "]\n",
    "\n",
    "def to_str(l):\n",
    "    return '+'.join(l)\n",
    "\n",
    "seed = random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbeClasses = [\n",
    "    LRProbe, \n",
    "    MMProbe, \n",
    "    ]\n",
    "\n",
    "accs = {str(probe_class) : {to_str(train_medley) : {} for train_medley in train_medlies} for probe_class in ProbeClasses}\n",
    "\n",
    "for ProbeClass in ProbeClasses:\n",
    "    for medley in train_medlies:\n",
    "\n",
    "        # set up data\n",
    "        dm = DataManager()\n",
    "        for dataset in medley:\n",
    "            dm.add_dataset(dataset, model, layer, split=split, seed=seed, noperiod=noperiod, center=True, device=device)\n",
    "        for dataset in val_datasets:\n",
    "            if dataset not in medley:\n",
    "                dm.add_dataset(dataset, model, layer, split=None, noperiod=noperiod, center=True, device=device)\n",
    "\n",
    "        # train probe\n",
    "        train_acts, train_labels = dm.get('train')\n",
    "        probe = ProbeClass.from_data(train_acts, train_labels, device=device)\n",
    "        direction = probe.direction\n",
    "\n",
    "        # evaluate\n",
    "        for val_dataset in val_datasets:\n",
    "            if val_dataset in medley:\n",
    "                acts, labels = dm.data['val'][val_dataset]\n",
    "                accs[str(ProbeClass)][to_str(medley)][val_dataset] = (\n",
    "                    probe.pred(acts, iid=True) == labels\n",
    "                ).float().mean().item()\n",
    "            else:\n",
    "                acts, labels = dm.data[val_dataset]\n",
    "                accs[str(ProbeClass)][to_str(medley)][val_dataset] = (\n",
    "                    probe.pred(acts, iid=False) == labels\n",
    "                ).float().mean().item()\n",
    "\n",
    "lr_mm_accs = accs.copy()\n",
    "\n",
    "######### File/path handling\n",
    "#experiment_name = \"generalization_results_v1\"\n",
    "#json_path = 'experimental_outputs/{}.json'.format(experiment_name)\n",
    "#with open(json_path, 'w') as file: # Make sure this file exists and is empty\n",
    "#    file.write('[]') \n",
    "#########\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    outs = json.load(f)\n",
    "\n",
    "for ProbeClass in ProbeClasses:\n",
    "    out = accs[str(ProbeClass)]\n",
    "    out['model'] = model\n",
    "    out['probe'] = ProbeClass.__str__()\n",
    "    out['layer'] = layer\n",
    "    out['oracle'] = False\n",
    "    out['noperiod'] = noperiod\n",
    "    outs.append(out)\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(outs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ccs_medlies = [\n",
    "#    ['cities', 'neg_cities'],\n",
    "#    ['larger_than', 'smaller_than'],\n",
    "#]\n",
    "#\n",
    "#accs = {to_str(medley) : {} for medley in ccs_medlies}\n",
    "#\n",
    "#for medley in ccs_medlies:\n",
    "#    dm = DataManager()\n",
    "#    for dataset in medley:\n",
    "#        dm.add_dataset(dataset, model, layer, split=split, seed=seed, noperiod=noperiod, center=True, device=device)\n",
    "#    for dataset in val_datasets:\n",
    "#        if dataset not in medley:\n",
    "#            dm.add_dataset(dataset, model, layer, split=None, noperiod=noperiod, center=True, device=device)\n",
    "#    \n",
    "#    train_acts, train_labels = dm.data['train'][medley[0]]\n",
    "#    train_neg_acts, _ = dm.data['train'][medley[1]]\n",
    "#    probe = CCSProbe.from_data(train_acts, train_neg_acts, train_labels, device=device)\n",
    "#\n",
    "#    for val_dataset in val_datasets:\n",
    "#        if val_dataset in medley:\n",
    "#            acts, labels = dm.data['val'][val_dataset]\n",
    "#        else:\n",
    "#            acts, labels = dm.data[val_dataset]\n",
    "#        accs[to_str(medley)][val_dataset] = (\n",
    "#            probe.pred(acts) == labels\n",
    "#        ).float().mean().item()\n",
    "#    \n",
    "#ccs_accs = accs.copy()\n",
    "#\n",
    "#with open('experimental_outputs/generalization_results.json', 'r') as f:\n",
    "#    outs = json.load(f)\n",
    "#\n",
    "#out = accs\n",
    "#out['model'] = model\n",
    "#out['probe'] = 'CCSProbe'\n",
    "#out['layer'] = layer\n",
    "#out['oracle'] = False\n",
    "#out['noperiod'] = noperiod\n",
    "#outs.append(out)\n",
    "#\n",
    "#with open('experimental_outputs/generalization_results.json', 'w') as f:\n",
    "#    json.dump(outs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get oracle probe results\n",
    "oracle_accs = {str(probe_class) : {} for probe_class in ProbeClasses}\n",
    "for ProbeClass in ProbeClasses:\n",
    "    for dataset in val_datasets:\n",
    "        dm = DataManager()\n",
    "        dm.add_dataset(dataset, model, layer, split=split, noperiod=noperiod, seed=seed, device=device)\n",
    "        acts, labels = dm.get('train')\n",
    "        probe = ProbeClass.from_data(acts, labels, device=device)\n",
    "\n",
    "        acts, labels = dm.data['val'][dataset]\n",
    "        acc = (probe(acts, iid=True).round() == labels).float().mean().item()\n",
    "        oracle_accs[str(ProbeClass)][dataset] = acc\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    outs = json.load(f)\n",
    "\n",
    "for ProbeClass in ProbeClasses:\n",
    "    out = oracle_accs[str(ProbeClass)]\n",
    "    out['model'] = model\n",
    "    out['probe'] = ProbeClass.__str__()\n",
    "    out['oracle'] = True\n",
    "    out['layer'] = layer\n",
    "    out['noperiod'] = noperiod\n",
    "    outs.append(out)\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(outs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['llama-2-7b', 'llama-2-13b', 'llama-2-70b']\n",
    "models = ['llama-13b']\n",
    "# ProbeClasses = [LRProbe, MMProbe, CCSProbe]\n",
    "ProbeClasses = [LRProbe, MMProbe]\n",
    "\n",
    "# load data\n",
    "with open(json_path, 'r') as f:\n",
    "    outs = json.load(f)\n",
    "\n",
    "accssss = {}\n",
    "averagesss = {}\n",
    "for model in models:\n",
    "    accsss = {}\n",
    "    averagess = {}\n",
    "    # get LR and MM results\n",
    "    for ProbeClass in [LRProbe, MMProbe]:\n",
    "        accss = {}\n",
    "        averages = {}\n",
    "        for train_medley in train_medlies:\n",
    "            for out in outs:\n",
    "                if out['model'] == model and out['probe'] == ProbeClass.__str__() and out['oracle'] == False:\n",
    "                    accs = out[to_str(train_medley)]\n",
    "                    break\n",
    "            accss[to_str(train_medley)] = accs\n",
    "            average = sum(accs.values()) / len(accs)\n",
    "            averages[to_str(train_medley)] = average\n",
    "        accsss[ProbeClass.__str__()] = accss\n",
    "        averagess[ProbeClass.__str__()] = averages\n",
    "\n",
    "    # get CCS results\n",
    "    #for ProbeClass in [CCSProbe]:\n",
    "    #    accss = {}\n",
    "    #    averages = {}\n",
    "    #    for train_medley in [['cities','neg_cities'], ['larger_than', 'smaller_than']]:\n",
    "    #        for out in outs:\n",
    "    #            if out['model'] == model and out['probe'] == ProbeClass.__str__() and out['oracle'] == False:\n",
    "    #                accs = out[to_str(train_medley)]\n",
    "    #                break\n",
    "    #        accss[to_str(train_medley)] = accs\n",
    "    #        average = sum(accs.values()) / len(accs)\n",
    "    #        averages[to_str(train_medley)] = average\n",
    "    #    accsss[ProbeClass.__str__()] = accss\n",
    "    #    averagess[ProbeClass.__str__()] = averages\n",
    "    \n",
    "    # get oracle results\n",
    "    for ProbeClass in ['oracle']:\n",
    "        accss = {}\n",
    "        for out in outs:\n",
    "            if out['model'] == model and out['oracle'] == True and out['probe'] == 'LRProbe':\n",
    "                accs = out\n",
    "        # filter for numbers\n",
    "        filtered_accs = {}\n",
    "        for val_dataset in val_datasets:\n",
    "            filtered_accs[val_dataset] = accs[val_dataset]\n",
    "        accsss['oracle'] = filtered_accs\n",
    "        averagess[ProbeClass.__str__()] = sum(filtered_accs.values()) / len(filtered_accs)\n",
    "\n",
    "    accssss[model] = accsss\n",
    "    averagesss[model] = averagess\n",
    "\n",
    "# get few-shot results\n",
    "#with open('experimental_outputs/few_shot_results.json', 'r') as f:\n",
    "#    few_shot_results = json.load(f)\n",
    "#for model in models:\n",
    "#    few_shot_accs = {}\n",
    "#    for dataset in val_datasets:\n",
    "#        all_accs = [d['acc'] for d in few_shot_results if (d['dataset'] == dataset and d['model'] == model)]\n",
    "#        few_shot_accs[dataset] = max(all_accs)\n",
    "#    accssss[model]['few_shot'] = few_shot_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5346548706293106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg(accssss, 'llama-13b', 'LRProbe', ['experiment_cps'], ['experiment_inter_stereoset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = {0 : 7, 1 : 13, 2 : 70}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'size'   : 14}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "def get_accs(full_accs, model, probe_type, medley, drop=[]):\n",
    "    accs = full_accs[model][probe_type][to_str(medley)].copy()\n",
    "    for d in drop:\n",
    "        del accs[d]\n",
    "    return accs\n",
    "\n",
    "def get_avg(full_accs, model, probe_type, medley, drop=[]):\n",
    "    accs = get_accs(full_accs, model, probe_type, medley, drop=drop)\n",
    "    return sum(accs.values()) / len(accs)\n",
    "\n",
    "#'experiment_cps',\n",
    "#    'experiment_inter_stereoset', # gender\n",
    "#    'experiment_intra_stereoset'\n",
    "\n",
    "\n",
    "plt.plot(get_avg(accssss, 'llama-13b', 'LRProbe', ['experiment_cps'], ['experiment_inter_stereoset']), 'r--', label='cities')\n",
    "#plt.plot(\n",
    "#    [get_avg(accssss, f'llama-2-{scales[i]}b', 'LRProbe', ['cities', 'neg_cities'], ['cities', 'neg_cities']) for i in range(len(scales))], 'r-', label='cities+neg_cities'\n",
    "#)\n",
    "#plt.plot(\n",
    "#    [get_avg(accssss, f'llama-2-{scales[i]}b', 'LRProbe', ['larger_than'], ['larger_than', 'smaller_than']) for i in range(len(scales))], 'b--', label='larger_than'\n",
    "#)\n",
    "#plt.plot(\n",
    "#    [get_avg(accssss, f'llama-2-{scales[i]}b', 'LRProbe', ['larger_than', 'smaller_than'], ['larger_than', 'smaller_than']) for i in range(len(scales))], 'b-', label='larger_than+smaller_than'\n",
    "#)\n",
    "#plt.plot(\n",
    "#    [averagesss[f'llama-2-{scales[i]}b']['oracle'] for i in range(len(scales))], 'k-', label='LR on test set (oracle)'\n",
    "#)\n",
    "# plt.plot(\n",
    "#     [averagesss[f'llama-2-{scales[i]}b']['LRProbe']['likely'] for i in range(len(scales))], '-', color='gray', label='likely'\n",
    "# )\n",
    "\n",
    "# set x ticks\n",
    "plt.xticks(range(len(scales)), [f'{scales[i]}B' for i in range(len(scales))])\n",
    "\n",
    "plt.ylabel('OOD accuracy')\n",
    "\n",
    "plt.ylim(0.4, 1)\n",
    "plt.legend()\n",
    "plt.savefig('generalization_v1.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['LRProbe']['cities+neg_cities'] for i in range(3)], 'r-',\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['MMProbe']['cities+neg_cities'] for i in range(3)], 'r--'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['CCSProbe']['cities+neg_cities'] for i in range(3)], 'r:'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['LRProbe']['larger_than+smaller_than'] for i in range(3)], 'b-'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['MMProbe']['larger_than+smaller_than'] for i in range(3)], 'b--'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['CCSProbe']['larger_than+smaller_than'] for i in range(3)], 'b:'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['oracle'] for i in range(3)], 'k-'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['LRProbe']['likely'] for i in range(3)], '-', color='gray'\n",
    ")\n",
    "plt.plot(\n",
    "    [averagesss[f'llama-2-{scales[i]}b']['MMProbe']['likely'] for i in range(3)], '--', color='gray'\n",
    "\n",
    ")\n",
    "plt.ylim(0.4, 1)\n",
    "\n",
    "plt.xticks(range(len(scales)), [f'{scales[i]}B' for i in range(len(scales))])\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.ylim(0.4, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "model = 'llama-2-7b'\n",
    "\n",
    "def make_axis(ax, model, probe_type, medlies):\n",
    "    grid = [ [None for _ in medlies] for _ in val_datasets]\n",
    "    for i, dataset in enumerate(val_datasets):\n",
    "        for j, medley in enumerate(medlies):\n",
    "            grid[i][j] = get_accs(accssss, model, probe_type, medley)[dataset]\n",
    "    ax.imshow(grid, vmin=0, vmax=1)\n",
    "\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[0])):\n",
    "            ax.text(j, i, f'{round(grid[i][j] * 100):2d}', ha='center', va='center')\n",
    "\n",
    "    ax.set_xticks(range(len(medlies)))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "make_axis(axes[0], model, 'LRProbe', [['cities'], ['cities', 'neg_cities'], ['larger_than'], ['larger_than', 'smaller_than']])\n",
    "\n",
    "make_axis(axes[1], model, 'MMProbe', [['cities'], ['cities', 'neg_cities'], ['larger_than'], ['larger_than', 'smaller_than']])\n",
    "\n",
    "make_axis(axes[2], model, 'CCSProbe', [['cities', 'neg_cities'], ['larger_than', 'smaller_than']])\n",
    "\n",
    "# grid = [ [None for _ in range(4)] for _ in val_datasets]\n",
    "# for i, dataset in enumerate(val_datasets):\n",
    "#     grid[i][0] = get_accs(accssss, model, 'LRProbe', ['likely'])[dataset]\n",
    "#     grid[i][1] = get_accs(accssss, model, 'MMProbe', ['likely'])[dataset]\n",
    "#     grid[i][2] = accssss[model]['few_shot'][dataset]\n",
    "#     grid[i][3] = accssss[model]['oracle'][dataset]\n",
    "# axes[2].imshow(grid, vmin=0, vmax=1)\n",
    "# axes[2].set_xticks(range(4))\n",
    "# axes[2].set_xticklabels([])\n",
    "# axes[2].set_yticks([])\n",
    "# axes[2].set_yticklabels([])\n",
    "\n",
    "# for i in range(len(grid)):\n",
    "#     for j in range(len(grid[0])):\n",
    "#         axes[2].text(j, i, f'{round(grid[i][j] * 100):2d}', ha='center', va='center')\n",
    "\n",
    "# axes[0].set_yticks(range(len(val_datasets)))\n",
    "# axes[0].set_yticklabels([])\n",
    "\n",
    "# add colorbar\n",
    "# plt.colorbar(axes[0].images[0])\n",
    "\n",
    "fig.savefig('junk/llama-2-7b_generalization.pdf')\n",
    "fig.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
